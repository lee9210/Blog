title: Kafka 是什么
date: 2018-10-23
tags:
categories: 精进
permalink: Fight/What-is-kafka
author: 阿飞
from_url: http://www.jianshu.com/p/8d7f30f87f95
wechat_url:

----

摘要: 原创出处 http://www.jianshu.com/p/8d7f30f87f95 「阿飞」欢迎转载，保留摘要，谢谢！

- [定义](http://www.iocoder.cn/Fight/What-is-kafka/)
- [架构](http://www.iocoder.cn/Fight/What-is-kafka/)
- [topic](http://www.iocoder.cn/Fight/What-is-kafka/)
- [durable](http://www.iocoder.cn/Fight/What-is-kafka/)
- [consumer](http://www.iocoder.cn/Fight/What-is-kafka/)
- [consumer group](http://www.iocoder.cn/Fight/What-is-kafka/)

-------

![](http://www.iocoder.cn/images/common/wechat_mp_2017_07_31.jpg)

> 🙂🙂🙂关注**微信公众号：【芋道源码】**有福利：
> 1. RocketMQ / MyCAT / Sharding-JDBC **所有**源码分析文章列表
> 2. RocketMQ / MyCAT / Sharding-JDBC **中文注释源码 GitHub 地址**
> 3. 您对于源码的疑问每条留言**都**将得到**认真**回复。**甚至不知道如何读源码也可以请教噢**。
> 4. **新的**源码解析文章**实时**收到通知。**每周更新一篇左右**。
> 5. **认真的**源码交流微信群。

-------

# 定义

一千个人眼里有一千个哈姆雷特。如果说谁最有资格定义kafka是什么，那么肯定是官方文档：

```java
Apache Kafka® is a distributed streaming platform.
```

官方还对流平台进行了定义--流平台有三大关键能力（A streaming platform has three key capabilities）：

- Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system.
- Store streams of records in a fault-tolerant durable way.
- Process streams of records as they occur.

第一个特性是类MQ的发布订阅特性，第二个特性就是具备容错的存储能力，第三个特性是处理数据。所以kafka可以替代ActiveMQ这类消息中间件。另外我们看一下官方对kafka的定位，如下图所示：

![kafka定位](https:////upload-images.jianshu.io/upload_images/6918995-ea4d7e038243c7c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/846/format/jpeg)

kafka几个重要的概念:

- Kafka is run as a cluster on one or more servers that can span multiple datacenters.
- The Kafka cluster stores streams of records in categories called topics.
- Each record consists of a key, a value, and a timestamp.

# 架构

kafka架构如下图所示，消息中间件的本质就是：**生产-存储-消费**。由下图可知，在kafka的架构设计里，无论是生产者，还是消费者，还是消息存储，都可以水平扩容从而提高整个集群的处理能力，生来就是分布式系统。另外，图中没有展示出来的kafka另一个很重要的特性，那就是副本，在创建topic的时候指定分区数量的同时，还可以指定副本的数量（副本最大数量不允许超过broker的数量，否则会报错：Replication factor: 2 larger than available brokers: 1）。各个副本之间只有一个leader，其他是follow，只有leader副本提供读写服务，follow副本只是冷备，当leader挂掉会从follow中选举一个leader，从而达到高可用。

![kafka architecture](https:////upload-images.jianshu.io/upload_images/6918995-c50ce98319677c06.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/858/format/jpeg)


> 图片来源于`https://en.wikipedia.org/wiki/File:Overview_of_Apache_Kafka.svg`

# topic

下图是topic的解剖图，kafka只有topic的概念，没有类似ActiveMQ中的Queue（一对一）的概念（ActiveMQ既有Topic又有Queue）。一个topic可以有若干个分区，且分区可以动态修改，但是只允许增加不允许减少。每个分区中的消息是有序的。各个分区之间的消息是无序的。新消息采用追加的方式写入，这种顺序写入方式，从而使kafka的吞吐能力非常强大（一些验证表名顺序写入磁盘的速度超过随机写入内存）。



![kafka topic](https:////upload-images.jianshu.io/upload_images/6918995-75ed3cc390a1cc9b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/748/format/jpeg)



- topic定义
   官方定义：A topic is a category or feed name to which records are published. Topics in Kafka are always multi-subscriber; that is, a topic can have zero, one, or many consumers that subscribe to the data written to it.
   例如订单支付成功后，发送名为`TOPIC_PAYMENT_ORDER_SUCCESS`，积分系统可以接收这个topic，给用户送积分。会员系统可以接收这个topic，增加会员成长值。支付宝里的蚂蚁庄园还有支付成功后送饲料等。

- 磁盘&内存速度对比
   由下图可知，顺序写入磁盘的速度（Sequential, disk）为53.2M，而随机写入内存的速度（Random, memory）为36.7M。



  ![磁盘&内存速度对比](https:////upload-images.jianshu.io/upload_images/6918995-935190691611febf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/585/format/jpeg)


> 图片来源于网络：<http://searene.me/2017/07/09/Why-is-Kafka-so-fast/>

# durable

kafka对消息日志的存储策略为：The Kafka cluster durably persists all published records—whether or not they have been consumed—using a configurable retention period. For example, if the retention policy is set to two days, then for the two days after a record is published, it is available for consumption, after which it will be discarded to free up space. Kafka's performance is effectively constant with respect to data size so storing data for a long time is not a problem.
 即无论如何，kafka会持久化保存所有消息，无论它们是否已经被消费。而kafka消息日志保留策略通过配置决定（以`log.retention`开头的一些配置，例如`log.retention.ms`，`log.retention.minutes`，`log.retention.hours`，`log.retention.bytes`），例如配置有效期两天，那么两天内这些消息日志都能通过offset访问。到期后，kafka会删除这些消息日志文件释放磁盘空间。

# consumer

kafka消费topic中某个分区示意图如下，至于kafka如何在各个topic的各个分区中选择某个分区，后面的文章会提到。由下图可知，消费者通过offset定位并读取消息，且各个消费者持有的offset是自己的消费进度。



![kafka consumer](https:////upload-images.jianshu.io/upload_images/6918995-60cc0a5474876929.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/872/format/jpeg)

# consumer group

- each record published to a topic is delivered to one consumer instance within each subscribing consumer group. Consumer instances can be in separate processes or on separate machines.
- If all the consumer instances have the same consumer group, then the records will effectively be load balanced over the consumer instances.
- If all the consumer instances have different consumer groups, then each record will be broadcast to all the consumer processes.

即对于订阅了某个topic的consumer group下的所有consumer，任意一条消息只会被其中一个consumer消费。如果有多个consumer group，各个consumer group之间互不干扰。consumer group示意图如下所示，某个topic消息有4个分区：P0, P1, P2, P3。Consumer Group A中有两个consumer：C1和C2。Consumer Group B中有4个consumer：C3，C4，C5和C6。如果现在生产者发送了一条消息，那么这条消息只会被Consumer Group A中的C1和C2之中某个消费者消费到，以及被Consumer Group B中的C3，C4，C5和C6之中某个消费者消费到。


![consumer group](https:////upload-images.jianshu.io/upload_images/6918995-2f66a2b6ce7d84b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/799/format/jpeg)